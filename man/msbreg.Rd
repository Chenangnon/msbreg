% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/msbreg.R
\name{msbreg}
\alias{msbreg}
\alias{msbm.fit}
\title{Fitting Multistage Binomial Regression Models}
\usage{
msbreg (formula,
        input.me = list(),
        stage.me = NULL,
        alpha.formula = ~ 0,
        lambda.formula = ~ 1,
        kappa.formula = ~ 0,
        link = "logit",
        data = environment(formula),
        weights = NULL, sample.weights = NULL,
        subset = NULL, na.action = stats::na.omit,
        offset, start = NULL, control = list(...),
        y = TRUE, frame = FALSE, method = "msbm.fit",
        ...)

msbm.fit (frame, y = frame$y,
          start = NULL,
          link = "logit",
          control = list(),
          singular.ok = TRUE)
}
\arguments{
\item{formula}{an object of class "\link[stats]{formula}" (or one
that can be coerced to that class), a symbolic description of the
MSB model to be fitted.
See \link[msbreg]{msbm.frame} for how the \code{formula} argument
is interpreted (and should be built).
See \link[msbreg]{msbreg-package} for an introduction to the MSB model.}

\item{input.me, stage.me}{optional list of one sided \link[stats]{formula}
objects (\code{input.me}) or one sided \link[stats]{formula} object
(\code{stage.me}) specifying standard deviations for numerical
offsets or predictors in \code{formula}. See \link[msbreg]{msbm.frame}
for details.}

\item{alpha.formula, lambda.formula}{optional one sided \link{formula} objects
specifying covariates to be included in the linear predictors for \eqn{\alpha}
(parameter that determines the minimum success probability of the binomial
response variable) and \eqn{\lambda} (the maximum success probability of
the binomial response) in the MSB model. The default behavior assumes that
\eqn{\alpha = 0} and \eqn{\lambda} is an unknown constant to be
estimated (\eqn{\lambda \in (0, 1]}).}

\item{kappa.formula}{optional one sided \link{formula} object specifying
covariates to be included in the linear predictor for a real parameter
that determines the dependence between
the Bernoulli counts that made up each binomial response, applicable when
the number of trials (Bernoulli experiments) is greater than one.
The default behavior assumes that \eqn{\kappa = 1}.

This is a planned feature of the \code{msbreg} package, currently not
implemented. When applicable, specifying \code{kappa.formula} would replace
the usual binomial distribution by a Conway-Maxwell-Binomial distribution (CMB)
\insertCite{kadane2016sums}{msbreg} for log-likelihood calculations, allowing
both positive (\eqn{-\infty < \kappa < 1}) and negative (\eqn{1 < \kappa < \infty})
dependence when modelling binomial counts resulting from multistage designs.
Of course, the CMB distribution is  reduced to the binomial distribution
when \eqn{\kappa = 1}.}

\item{link}{a description of the link function to be used in the model.
For \code{msbreg}, a character giving the name of the link function
to be used. Alternatively, \code{link} can be an object of class
\code{"link"}, or a function such that \code{link()} returns an object
of class \code{"link"}. Defaults to the \link[msbreg]{logit} \code{link}.

For a model without measurement error for any predictor, any link accepted
by the \link[stats]{binomial} family for \link[stats]{glm} is also accepted
by \code{msbreg}. When measurement errors are present, only
\link[msbreg]{logit} and \link[msbreg]{probit} links are currently
available.

\strong{PS}: for \code{msbreg}, when specifying \code{link} as a function call
or a character, care should be taken to avoid function related conflicts
between package namespaces. For instance, the package \code{boot} contains
a function \code{logit} and thus, loading the package \code{boot} after
loading \code{msbreg} would mask the \code{logit} function in \code{msbreg}.
Since \code{msbreg} imports functions from \code{boot}, that case has been
specifically handled to avoid the related conflict. But such conflicts
are possible and would generally result into errors. A simple
specification rule to avoid error is to use codes of the form
\code{link = msbreg::logit()} or \code{link = msbreg::probit()} when
conflicts are suspected.}

\item{data, weights, subset, na.action}{Same as for \link[stats]{glm}.
See \link[msbreg]{msbm.frame} for details.}

\item{sample.weights}{\code{NULL} (default) or an optional vector of subject
weights in the sampled population. See section \emph{Observation weights} in
\link[msbreg]{msbm.frame} for details.}

\item{offset}{place holder, not used. It appears as a named argument
only to ensure that it is not included in the \code{...} arguments.
See section \strong{Details} in \link[msbreg]{msbm.frame} for how to
include offsets in MSB model components.}

\item{start}{\code{NULL} (default) or a vector of starting values for model
parameters. Note that unlike for the function \link[stats]{glm}, \code{msbreg}
has many linear predictors, one for each MSB model stage (in \code{formula})
and possibly one for each of the lower and upper limits of the response
success probability (in \code{alpha.formula} and \code{lambda.formula}).
The elements of \code{start} must be ordered as in \code{formula},
then followed by \code{alpha.formula} and finally \code{lambda.formula}.}

\item{control}{a list of parameters passed to \link[msbreg]{msbm.control}
for controlling the fitting process. See arguments \code{...} for an
alternative route to pass control details to \link[msbreg]{msbm.control}.}

\item{y}{For \code{msbreg}: logical value indicating whether the
response vector used in the fitting process should be returned as
a component of the returned value.

For \code{msbm.fit}: numeric vector of binomial responses which (when
supplied) is substituted to the \code{y} component of the supplied
model frame (\code{frame}).}

\item{frame}{For \code{msbreg}: a logical value indicating whether the
\emph{model frame} (of class "\link[msbreg]{msbm.frame}") should be included
as a component of the returned object.

For \code{msbm.fit}: a "\link[msbreg]{msbm.frame}" class object which
provides the structure and content of the design matrices in the MSB model.}

\item{method}{the method to be used in fitting the model.
The default \code{method = "msbm.fit"} uses a numerical algorithm
such as those implemented by \link[stats]{optim} to directly maximize
the (penalized) log-likelihood function, or those in the package \code{BB}
to solve the score equation.

The alternative \code{method = "model.frame"} returns the model frame
(of class "\link[msbreg]{msbm.frame}") and does no fitting.}

\item{...}{further named arguments to pass to or from other methods.
Currently, \code{frames} is passed to \link[msbreg]{msbm.frame};
and any formal argument of \link[msbreg]{msbm.control} is passed
to that function.}

\item{singular.ok}{logical, if \code{FALSE} a singular fit is an error.
A \emph{singular fit} is defined as one with a singular Fisher information matrix.}
}
\value{
\code{msbreg} returns an object inheriting from class
\code{"msbm"} which is a list with the following elements:

\item{\code{coefficients}}{ a named vector of coefficients (estimates of all
model parameters), the names of the coefficients are taken from the
vector \code{start}, and if \code{start} is NULL or has no name attribute,
the names are taken from the model frame;}

\item{\code{fitted.values}}{ the fitted mean values of the success
probability of the binary response; obtained by transforming the
linear predictors in different MSB components by the inverse of
the link function, and combining these transforms;}

\item{\code{alpha.values}}{ the fitted values of the \eqn{\alpha}
component of the MSB model; when \code{alpha.formula} contains
neither a predictor nor an offset (this is the case for the default
\code{alpha.formula = ~ 0}), the returned \code{alpha.values} is not
a vector but a scalar;}

\item{\code{lambda.values}}{ the fitted values of the \eqn{\lambda}
component of the MSB model (a scalar if \code{lambda.formula} does
not have any predictor/offset);}

\item{\code{rank}}{ the numeric rank of the fitted MSB model; a \code{rank}
value less than the number of model parameters (length of \code{coefficients})
indicates an overparametrized fit;}

\item{\code{null.rank}}{ the numeric rank of the null MSB model;}

\item{\code{link}}{ the "\link[msbreg]{link}" object used;}

\item{\code{linear.predictors}}{ matrix of linear fits on link scale,
including one column for each model stage, and one column for each of
the \eqn{\alpha} and \eqn{\lambda} components;}

\item{\code{aic}, \code{bic}, \code{hqc}}{ common information criteria of the general
form \eqn{-2 ll + k n_{pars}} where \eqn{ll} is the log-likelihood,
\eqn{n_{pars}} is the number of estimated parameters in the fitted model,
and \eqn{k = 2} for \code{aic} (\emph{Akaike's Information Criterion}),
\eqn{k = log(n)} for \code{bic} (\emph{Schwarz's Bayesian Criterion}), and
\eqn{k = 2 log(log(n))} for \code{hqc} (\emph{Hannanâ€“Quinn Information Criterion});}

\item{\code{deviance}}{ the \emph{residual deviance}, that is, minus twice
the difference of log-likelihoods between the saturated model and the
fitted model (note: the saturated model assumes each data point has its own
parameters);}

\item{\code{deviance.resid}}{ the contributions of individual observations
to the residual \code{deviance} value, see e.g. Eq. (20) in
\insertCite{green1984iteratively;textual}{msbreg};}

\item{\code{null.deviance}}{ the deviance for the null model,
comparable with \code{deviance}; the null MSB model is defined
as follows:}

\itemize{
\item \eqn{\alpha} component: set to zero if \code{alpha.formula} has
no offset, otherwise set to the offset value(s);

\item \eqn{\lambda} component: set to one if \code{lambda.formula} has
no offset, otherwise set to the offset value(s);

\item MSB stages: each stage keeps its offset if it has one included in
\code{formula}; and one of the stages which have intercepts in \code{formula}
is allowed to include an intercept in the null model, the stage leading
to the highest null likelihood value is used.

It is worth noticing that any change to any offset in the model will
affect the null deviance. Keeping offsets unchanged, changes
to \code{alpha.formula} or \code{lambda.formula}, including adding or
dropping an intercept term, do not affect the null model. However,
adding or dropping an intercept from any model stage may affect the
null model and thus the null deviance.

The null model is reduced to the null \link[stats]{glm}
with the binomial family when the MSB model is reduced to a binomial GLM.
Note that, as for \link[stats]{glm}s, the inclusion of a non-\code{NULL}
offset in a null model will be incorrect if the \code{link} function
depends on the data other than through the fitted success
probabilities. In such instances, specify a zero offset to force
a correct calculation;
}

\item{\code{iter}}{ the \code{iter} component returned by
the fitter function; \code{msbm.fit} returns the number
of function evaluations used by \link[stats]{optim};}

\item{\code{nobs}}{ the total number of non-missing observations;}

\item{\code{weights}, \code{sample.weights}}{ the used vectors of
\emph{weights} (cases) and \emph{sample weights} (sampling weights);}

\item{\code{df.residual}}{ the residual degrees of freedom;}

\item{\code{df.null}}{ the residual degrees of freedom for
the null model;}

\item{\code{y}}{ if requested (the default) the used \code{y}
vector (it is a vector even for when the left hand side of argument
\code{formula} is a two-column matrix);}

\item{\code{y.resid}}{ the used \code{y} vector minus
the corresponding fitted values;}

\item{\code{converged}}{ logical, was the used algorithm
judged to have converged?}

\item{\code{boundary}}{ logical vector indicating if the
estimates in \code{coefficients} are on the boundary
of the attainable values;}

\item{\code{criterion}}{ the attained fit criterion. This is
evaluated after intercept-correction (if any, see the argument
\code{method} of \link[msbreg]{msbm.control}), but if applicable,
the returned \code{criterion} will have an attribute \code{"before.IC"}
giving the attained fit criterion before intercept-correction.
The returned \code{criterion} may have additional attributes
depending on the used fitting method.

For the default method (\code{method = "msbm.fit"}), the criterion
is the negative log-likelihood, possibly plus a penalty for small
sample bias correction depending on \code{control$method} (no
penalty for \code{control$method = "ML"}).
Here, \code{criterion} has the attribute
\code{hessian} which is the matrix of second order partial derivatives
of the fit criterion with respect to \code{coefficients};}

\item{\code{fisher}}{ the expected Fisher information matrix
of the MSB model, evaluated at \code{coefficients}.

For the default method (\code{method = "msbm.fit"}),
the component \code{$fisher} has the attributes:}

\itemize{
\item \code{qr}: a "\link{qr}" object giving the QR decomposition
of the returned \code{fisher} matrix;

\item \code{score}: the score of the log-likelihood function
(vector of first order partial derivatives with respect to model
parameters) evaluated at \code{coefficients};

\item \code{score.i}: matrix of empirical estimating functions,
i.e. individual contributions of non-missing observations to
the vector \code{score} (so that \code{score = colSums(score.i)});

\item \code{mu.coefficients}: matrix of the first order partial
derivatives (Jacobian) of the \code{fitted.values} with respect
to \code{coefficients}; and

\item \code{observed}: the observed information matrix
of the MSB model (i.e. the matrix of second order partial derivatives
of the log-likelihood function with respect to model parameters)
evaluated at \code{coefficients} (the attribute \code{observed} also
has a "\link{qr}" attribute);
}

\item{\code{singular}}{ logical, is the Fisher information singular?}

\item{\code{start}}{ the used vector \code{start} (either the
user-supplied \code{start} if any, or a self-starting vector of model
parameters otherwise).

For the default method (\code{method = "msbm.fit"}), \code{start} has the
attribute \code{"IC"} when intercept-correction has been applied: this
gives the initial guess of intercept coefficients for the
intercept-correction procedure, this initial guess is also
the estimate of the vector of intercept coefficients before
intercept correction;}

\item{\code{IC}}{ logical value, did the fitting method employ
intercept-correction?}

\item{\code{me}}{ logical value, does any of the predictors in the
model have measurement error?}

\item{\code{me.offset}}{ logical value, does any of the model stages
have known measurement error (offset)?}

\item{\code{me.sd}}{ \code{NULL} or a numeric matrix of standard deviations
of measurement errors (if any) per model stage (one column per stage);}

\item{\code{call}}{ the matched call to \code{msbreg};}

\item{\code{formula}, \code{data}, \code{control}, \code{method}}{
the corresponding used arguments;}

\item{\code{na.action}}{ (where relevant) information returned by
\link[msbreg]{msbm.frame} on the special handling of \link{NA}s;}

\item{\code{dims}}{ the \code{dims} component of the model frame (see
\link[msbreg]{msbm.frame} for details);}

\item{\code{frame}}{ if requested through the argument \code{frame = TRUE}
(the default), the model frame which is an "msbm.frame" class
object (with any \link{NA}s in measurement errors set to zero).}

If a non-standard fitter function \code{method} is used, the returned object
will also inherit from the class (if any) returned by that function (that
class is prepended to the \code{"msbm"} class).

The \code{"msbm"} class has specific \code{print} and \code{summary} methods
for summarizing and printing the output from a call to \code{msbreg}.
}
\description{
Fit Multistage Binomial (MSB) regression models specified by a symbolic
description of linear predictors (and optionally measurement errors) in
model components and a specification of the link function.
}
\details{
The Multistage Binomial (MSB) regression model
\insertCite{tovissode2025multistage}{msbreg} is an extension of the
Traditional Binomial model, that is, the generalized linear model based
on the binomial error distribution for the response variable.
See section \strong{Details} in \link[msbreg]{msbreg-package} for a brief
definition of a MSB model.

The model specification interface is provided by the function
\link[msbreg]{msbm.frame} whose documentation details the usage
modalities for most arguments. In particular, the argument
\code{formula} is similar to \link[stats]{glm} function's
\code{formula}, but has a left hand side indexing different MSB
model stages which are delineated by the symbol \code{"|"}.
See the section \strong{Details} in \link[msbreg]{msbm.frame}
for more details on model specification.

Arguments such as \code{weights}, \code{sample.weights}, \code{subset}
are all evaluated in the same way as variables in \code{formula},
\code{input.me}, \code{stage.me}, \code{alpha.formula} and \code{lambda.formula}:
that is first in \code{data} and then in the environment of \code{formula}.
Any \code{NA}s in measurement errors are set to zero.

Non-\code{NULL} \code{weights} can be used to indicate that different
observations (sampling units) result from different numbers of trials
(total cases) while non-\code{NULL} \code{sample.weights} can be used
to indicate that different sampling units represent different proportions
(strata) of the (total size of the) target population.

When \code{sample.weights} is non-\code{NULL}, the corresponding
vector of \emph{sample importances} is scaled to sum up to the number of
non-missing observations before fitting.
This ensures that the fit is invariant to the total
sum of \code{sample.weights}, only the relative weights count.

The function \code{msbm.fit} is the workhorse for model fitting:
it is not normally called directly but can be more efficient
where the model frame and starting parameter values (in the input
argument \code{start}) have already been determined.
As for \link[stats]{glm}s, the argument \code{method} allows the model frame
to be recreated with no fitting, and the default fitter \code{msbm.fit}
to be replaced by a function which takes the same arguments but uses a
different fitting algorithm. If \code{msbm.fit} is supplied as a character
string it is used to search for a function of that name, starting in the
\strong{msbreg} namespace.

It is worth mentioning the following possible elements of the list
argument \code{control} as used by the fitter \code{msbm.fit}:

\describe{
\item{\code{criterion}}{ character indicating the objective to be
optimized to find parameter estimates. Classical inference by Maximum
Likelihood estimation corresponds to \code{criterion = "ML"}. This can
however be overly biased in small samples because of the multiplicative
nature of the MSB model (see \link[msbreg]{msbreg-package}). Alternatives include
\emph{(i)} \code{"MLJ"} (the default) for Penalized \code{"ML"} with Jeffreys
invariant prior as penalty, \emph{(ii)} \code{"MLJIC"} for \code{"MLJ"} followed
by intercept-correction (re-estimation by "ML" while keeping slopes
fixed at their \code{"MLJ"} estimates) so that predicted probabilities
are unbiased to the first order, and \emph{(iii)} \code{"MLPJ"} for partial
\code{"MLJ"}, i.e. using the information matrix for only slopes in
Jeffreys prior calculation;}

\item{\code{method}}{ a character indicating the optimizer to consider for
the primary search of parameter estimates (currently uses
\code{"BFGS"} or \code{"Nelder-Mead"} from \link[stats]{optim});}

\item{\code{slope.signs}}{ \code{NULL}, or numeric vector indicating if regression
slopes in the MSB model should be forced to have some specific signs
(\code{-1} or \code{1}).}

\item{\code{unit.lambda}}{logical indicating whether a \emph{unit asymptote}
model (\eqn{\lambda = 1}) should be explored as part of the parameter
search procedure. This is ignored when \code{lambda.formula} does not include
an intercept term. When \code{lambda.formula} includes an intercept term,
the default is \code{unit.lambda = FALSE} if \code{lambda.formula} also
includes offsets. Otherwise, the default is \code{unit.lambda = TRUE}.
Note that setting \code{unit.lambda = TRUE} while  \code{lambda.formula}
includes offsets means that the offsets are ignored when considering
parameter values corresponding to \eqn{\lambda = 1} (infinite intercept
and null slopes).

When working on large datasets in contexts where \eqn{\lambda < 1}
is an established knowledge, setting \code{unit.lambda = FALSE} will
save the time spent searching the parameter space boundary.}
}

See \link[msbreg]{msbm.control} for further details on \code{control}.
}
\note{
See \link[msbreg]{msbreg-package} for an introduction to the multistage
binomial regression model framework.
}
\examples{
##** Infertility data
data ("infert", package = "datasets")

## Logistic regression fit to the infert data
GLMres <- glm (case ~ spontaneous,
               data = infert,
               family = binomial())

summary (GLMres)

## MSB model fit with a maximum success probability in [0, 1)
require(msbreg)
MSBres0 <- msbreg (case ~ spontaneous,
                   lambda.formula = ~ 1,
                   start = c(GLMres$coefficients, `(Intercept).lambda` = 0),
                   criterion = "ML",
                   data = infert)

summary (MSBres0)

#* The ML estimate of the asymptote is lambda = 0.8469 < 1.
#* But adding the additional asymptote parameter does not seem justified
#* (by the larger AIC as compared with the simple GLM).

#* This is in line with the profile likelihood plot:
profilelambda(MSBres0, plotit = TRUE, lambda = seq(0.5, 1, .01))

#* We can use a penalized likelihood estimation to make the
# likelihood surface less flat (default procedure)
MSBres <- msbreg (case ~ spontaneous,
                  lambda.formula = ~ 1,
                  start = c(GLMres$coefficients, `(Intercept).lambda` = 0),
                  data = infert)

summary (MSBres)

#* The penalized ML estimate of lambda is 1, on parameter space boundary
#* (as can be seen on the profile likelihood plot)
profilelambda(MSBres, plotit = TRUE, lambda = seq(0.6, 1, .01))

#* Use the score statistic to test H0: lambda = 1 versus H1: 0 < lambda < 1.
Sctest <- score.test(MSBres)
Sctest # lambda is not significantly lower than one

#* Plot the two model fits with the observed data
courbe(MSBres, col = 'red', xlim = c(-4, 5))
courbe(glm.to.msbm(GLMres), xlim = c(-4, 5), col = 'blue', add = TRUE)
legend(x = -4, y = 0.9, legend = c("GLM", "MSB"),
       col = c("red", "blue"), lty = c(1, 1))

# The two fits are different because of two distinct estimation methods:
# Maximum Likelihood vs Maximum A Posteriori with Jeffreys invariant prior

##** Simulated example 1: two-stage logistic model
data(test1data)
attr(test1data$y, "formula")

# Standard logistic fit
GLMres <- glm (y/Total ~ x1 + offset(off1) + x2,
               weights = Total,
               data = test1data,
               family = binomial())

summary (GLMres)

##Two-stage logistic model fit with a maximum success probability set to 1
# No multiplicative intercept
MSBres0 <- msbreg (y/Total ~ x1 + offset(off1) | x2,
                  lambda.formula = ~ 0,
                  weights = Total,
                  data = test1data)

summary (MSBres0)

##Two-stage logistic model fit with unknown maximum success probability
# A multiplicative intercept included
MSBres <- msbreg (y/Total ~ x1 + offset(off1) | x2,
                   lambda.formula = ~ 1,
                   weights = Total,
                   data = test1data)

summary (MSBres)

## AIC, HQC and BIC criteria: MSB models are fitter
cbind(AIC(GLMres, MSBres0, MSBres),
      HQC = HQC(GLMres, MSBres0, MSBres)[,2],
      BIC = BIC(GLMres, MSBres0, MSBres)[,2])

## Pseudo R-squared
# Squared-correlation between response and predictions
rsquared (GLMres, MSBres0, MSBres, method = "COR")

# Deviance reduction ratio (KL)
# (not appropriate for comparing GLMres vs MSBres0 or MSBres
#  because the null deviances differ)
rsquared (MSBres0, MSBres)

# True coefficients versus estimates from the best fit
cbind(Truth = attr(test1data$y, "theta"),
      Estimate = MSBres$coefficients)

# Fitting a model with known alpha and lambda components:
# lambda = 0.85 and alpha = .05/.85 (so that 0.05 is the minimum probability)
MSBresk <- msbreg (y/Total ~ x1 + offset(off1) | x2,
                   alpha.formula = ~ offset(qlogis(0.05/0.85)) - 1,
                   lambda.formula = ~ offset(qlogis(0.85)) - 1,
                   weights = Total,
                   data = test1data)
# In 'alpha.formula' and 'lambda.formula':
# 'qlogis' transforms alpha or lambda to link scale (use 'qnorm' for probit link)
# 'offset' declares the transformed values as known, to be kept fixed.
# '-1' indicates the absence of an intercept (none to be estimated).

summary (MSBresk)

# Note that the null deviance is different for this model as compared to others.

AIC(GLMres, MSBres0, MSBres, MSBresk)

##** Simulated example 2: fitting MSB model
#       with error-prone continuous predictors,
#       and a categorical predictor.

##* Simulate predictors
set.seed(167)
mdf <- data.frame(x1 = rexp(1000, 0.5),
                  # First continuous predictor
                  x2 = rnorm(1000),
                  # Second continuous predictor
                  x3 = rpois(1000, 5),
                  # Numeric, but discrete predictor
                  f1 = rep(c('a', 'b', 'c'),
                           length.out = 1000))
                  # Factor with three levels

##* Generate a response vector using the predictors
#   considering two stages
mframe <- sim.msb (formula = ~ x1 + f1 | x2 + x3,
                   data = mdf,
                   link = 'probit',
                   theta = c(3, -1, 0, 0.5, 3, -1, -0.5, 1.7),
                   seed = NULL)

mframe$frame # model frame
summary(mframe$y) # binary response

# Add the simulated response to the dataset
mdf$y <- mframe$y

# Simulate error-prone predictors
mdf$SDx1 <- abs(rnorm(1000, sd = 0.5))
mdf$SDx2 <- abs(rnorm(1000, sd = 0.5))
mdf$x1err <- rnorm(n = 1000, mean = mdf$x1, sd = mdf$SDx1)
mdf$x2err <- rnorm(n = 1000, mean = mdf$x2, sd = mdf$SDx2)

##* Fit the model, considering the error-prone predictors
MSBfit <- msbreg(formula = y ~ x1err + f1| x2err + x3,
                 input.me = list(x1err = ~ SDx1,
                                 x2err = ~ SDx2),
                 data = mdf,
                 link = 'probit',
                 criterion = 'ML')

summary (MSBfit)
# Compare the coefficient estimates to the true
# coefficients: (3, -1, 0, 0.5, 3, -1, -0.5, 1.7)

}
\references{
\insertAllCited{}
}
\seealso{
These are all methods for the \code{"msbm"} class:

\itemize{
\item \link[msbreg]{summary.msbm} to summarize and print
\code{"msbm"} class objects;

\item \link[msbreg]{residuals.msbm} to extract
fit elements such as deviance, and different types of residuals;

\item \link[msbreg]{rsquared} to compute pseudo-\eqn{R^2} for a
\code{"msbm"} fit;

\item \link[msbreg]{update.msbm} to update the \code{"msbm"}
call or fit;

\item \link[msbreg]{bootfit.msbm} to bootstrap a \code{"msbm"}
fit;

\item \link[msbreg]{MCmsbm} to run Monte Carlo simulations
with possibly many multistage binomial models; and

\item\link[msbreg]{simulate.msbm} to generate pseudo-random
realizations of the response vector of a multistage binomial model.
}

Also see \link[msbreg]{glm.to.msbm} for converting a \code{"glm"} object
into a \code{"msbm"} object, \link[msbreg]{sim.msbdata} for simulating
a MSB response when a fitted \code{"msbm"} class object is not yet available.
}
\author{
Chenangnon Tovissode working under Craig Miller at the
University of Idaho. The design (code structure) was inspired by the
architecture of the \link[stats]{glm} function.
}
